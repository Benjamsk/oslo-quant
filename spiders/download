#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import argparse
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
import multiprocessing

from osloquant.spiders.netfonds import NetfondsSpider
from osloquant.spiders.nasdaqomx import NasdaqOmxSpider

parser = argparse.ArgumentParser(description="Download market data")
parser.add_argument("--all", action="store_true", help="Download from all markets")
parser.add_argument("--oslobors", action="store_true", help="Download from Oslo BÃ¸rs")
parser.add_argument("--nasdaqomx", action="store_true", help="Download from NasdaqOMX")
args = parser.parse_args()

# if no arguments were given
if len(sys.argv) == 1:
    parser.print_help()

# create a crawler process if any of the spiders were requested
if args.all or args.oslobors or args.nasdaqomx:
    process = CrawlerProcess(get_project_settings())
    
if args.all or args.oslobors:
    process.crawl(NetfondsSpider)

if args.all or args.nasdaqomx:
    process.crawl(NasdaqOmxSpider)
    
# start the crawler process, if it has been created
try:
    process.start()
except:
    pass
